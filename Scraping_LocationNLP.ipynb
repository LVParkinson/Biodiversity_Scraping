{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Observer\n",
    "\n",
    "## A project to collect the thousands of observations of the natural world from Reddit (and maybe eventually other social media). Photos, identification, and any location information are collated to create a usable dataset for citizen science networks such as eBird and iNaturalist. We hope... eventually...\n",
    "\n",
    "### Authors: Lindsey Parkinson, Thomas Oliver, and Roman Grisch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses the Reddit API PRAW. You must have a Reddit account in order to use the notebook. I have my information saved in a seperate json file for anonymity. You can add your own credentials below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import praw\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "#redditkeys.json contains all the information necessary to use the Reddit API\n",
    "working_directory = os.getcwd()\n",
    "file_path = working_directory + '/redditkeys.json'\n",
    "\n",
    "with open(file_path) as infile:\n",
    "    credentials = json.load(infile)\n",
    "reddit = praw.Reddit(client_id = credentials[\"client_id\"],\n",
    "                     client_secret = credentials[\"client_secret\"],\n",
    "                     user_agent=credentials[\"user_agent\"],\n",
    "                     username=credentials[\"username\"],\n",
    "                     password=credentials[\"password\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parker09\n"
     ]
    }
   ],
   "source": [
    "#check to ensure it is associated with your Reddit account:\n",
    "#print(reddit.user.me())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many r/whatisthis___ or r/whatsthis___ subreddits used for plant, animal, and fungus identification. Here we use r/whatsthisfish as an example though multiple subreddits can be added to subreddit_list below. \n",
    "\n",
    "Other subreddits include:\n",
    "r/whatisthisfish,\n",
    "r/whatsthisbug,\n",
    "r/whatsthisbird,\n",
    "r/whatsthissnake\n",
    "\n",
    "The subreddits above follow a standard protocol enforced by the moderators making the scraping of novel observations easier. However, the following subreddits may also be worth considering:\n",
    "r/slimemolds,\n",
    "r/whatsthisplant,\n",
    "r/animalid,\n",
    "r/PlantIdentification,\n",
    "r/treeidentification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whatsthisfish completed; total 100 posts scraped\n"
     ]
    }
   ],
   "source": [
    "date_list = []\n",
    "#author_list = []\n",
    "id_list = []\n",
    "link_flair_text_list = []\n",
    "title_list = []\n",
    "url_list = []\n",
    "top_comment_list = []\n",
    "\n",
    "\n",
    "#subreddits we want to scrape information from\n",
    "subreddit_list= ['whatsthisfish']\n",
    "\n",
    "#What information we want from each subreddit post\n",
    "for subred in subreddit_list:\n",
    "    subreddit = reddit.subreddit(subred)\n",
    "    top_post = subreddit.top(limit = 100)  #how many posts from the subreddit we want to pull\n",
    "    \n",
    "    for sub in top_post:        \n",
    "        date_list.append(datetime.datetime.fromtimestamp(sub.created_utc))\n",
    "        #author_list.append(sub.author)\n",
    "        id_list.append(sub.id)        \n",
    "        link_flair_text_list.append(sub.link_flair_text)\n",
    "        title_list.append(sub.title)\n",
    "        url_list.append(sub.url)\n",
    "        \n",
    "    print(subred, 'completed; ', end='')\n",
    "    print('total', len(title_list), 'posts scraped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Date': date_list,\n",
    "                   'ID':id_list, \n",
    "                   #'Author':author_list, \n",
    "                   'Title':title_list,\n",
    "                   'Flair':link_flair_text_list,\n",
    "                   'URL':url_list\n",
    "                  })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(row, col = \"URL\"):\n",
    "    \"\"\"\n",
    "    This function will convert strings into hyperlinks readable when exported into csv or pdf. \n",
    "    Should make it easier to pull images\n",
    "    \"\"\"\n",
    "    return \"<a href='{}'>{}</a>\".format(row[col], row.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['URL'] = df.apply(convert, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting top comment\n",
    "This code extracts the comment tree of the first comment block then the first comment of the block. Our hope was that this comment will contain the correct identification because participants are supposed to upvote the answers they agree with. \n",
    "\n",
    "I added the if/else statement below to try and deal with posts that don't seem to have comments. Honestly, It doesn't work. Some subreddits I scrape the comment column ends up 1 or 2 rows shorter and I haven't figured out why.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = defaultdict(list)\n",
    "            \n",
    "for ID in id_list:\n",
    "    submission = reddit.submission(str(ID))\n",
    "    for top_level_comment in submission.comments:\n",
    "        if top_level_comment is not None:\n",
    "            comments[submission.title].append(top_level_comment.body)\n",
    "        else:\n",
    "            comments[submission.title].append(\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_comment = []\n",
    "    \n",
    "for key, val in comments.items():\n",
    "    if val is not None:\n",
    "        top_comment.append(val[0])\n",
    "    else:\n",
    "        top_comment.apend(\"NA\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[\"Top Comment\"] = top_comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting location\n",
    "The location of the observation should be written within the title of the post. In the following code chunks we use the nltk package to tokenize the post titles and attempt to extract location words.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and download NLP tools\n",
    "\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('maxent_ne_chunker')\n",
    "#nltk.download('words')\n",
    "#nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#A function to pull location information from Reddit post titles\n",
    "def extract_entity_names(t):\n",
    "    entity_names = []\n",
    "\n",
    "    if hasattr(t, 'label') and t.label:\n",
    "        if t.label() == 'NE':\n",
    "            entity_names.append(' '.join([child[0] for child in t]))\n",
    "        else:\n",
    "            for child in t:\n",
    "                entity_names.extend(extract_entity_names(child))\n",
    "    return entity_names\n",
    "\n",
    "titles_list = df[\"Title\"].tolist()\n",
    "location = []\n",
    "\n",
    "for item in titles_list:\n",
    "    sentences = nltk.sent_tokenize(item)\n",
    "    tokenized_sentences = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "    tagged_sentences = [nltk.pos_tag(sentence) for sentence in tokenized_sentences]\n",
    "    chunked_sentences = nltk.ne_chunk_sents(tagged_sentences, binary=True)\n",
    "    \n",
    "    entities = []  \n",
    "    for tree in chunked_sentences:\n",
    "        entities.extend(extract_entity_names(tree))\n",
    "    location.append(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Flair</th>\n",
       "      <th>URL</th>\n",
       "      <th>Top Comment</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-26 04:40:05</td>\n",
       "      <td>ji7jvh</td>\n",
       "      <td>Anybody know what species this is? Found in Ja...</td>\n",
       "      <td>Identified, probably</td>\n",
       "      <td>&lt;a href='https://i.redd.it/bybemwp61dv51.jpg'&gt;...</td>\n",
       "      <td>Florida pompano,  *Trachinotus carolinus* . Th...</td>\n",
       "      <td>[Anybody, Jacksonville, Inshore]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-15 00:58:58</td>\n",
       "      <td>h93riw</td>\n",
       "      <td>Caught in key west, Florida. Never seen anythi...</td>\n",
       "      <td>Identified, high confidence</td>\n",
       "      <td>&lt;a href='https://i.redd.it/j86d87vnhy451.jpg'&gt;...</td>\n",
       "      <td>Took me awhile, but its a swallow-tailed bass ...</td>\n",
       "      <td>[Caught, Florida]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-11 17:59:31</td>\n",
       "      <td>ghq9mn</td>\n",
       "      <td>I found this video and the fish is hella cute ...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://v.redd.it/lvximb7tr5y41'&gt;2&lt;/a&gt;</td>\n",
       "      <td>Looks like spotted porcupinefish also known as...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-21 17:49:37</td>\n",
       "      <td>l2299m</td>\n",
       "      <td>Picture taken in Central Florida. Freshwater p...</td>\n",
       "      <td>Family known, species unidentified</td>\n",
       "      <td>&lt;a href='https://i.redd.it/ow7f7ozctpc61.jpg'&gt;...</td>\n",
       "      <td>Common pleco. Non-native species in Florida.</td>\n",
       "      <td>[Picture, Central Florida, Freshwater]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-11-20 22:01:29</td>\n",
       "      <td>jxxfdr</td>\n",
       "      <td>What's this crustacean? Has a short lobster li...</td>\n",
       "      <td>Identified, high confidence</td>\n",
       "      <td>&lt;a href='https://v.redd.it/c8cfmpcrlg061'&gt;4&lt;/a&gt;</td>\n",
       "      <td>Pretty sure its a Slipper Lobster.</td>\n",
       "      <td>[Florida]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2020-11-27 07:00:16</td>\n",
       "      <td>k1vk0j</td>\n",
       "      <td>What is this \"rare elongated fish\" caught off ...</td>\n",
       "      <td>Identified, high confidence</td>\n",
       "      <td>&lt;a href='https://i.redd.it/8nxx9mfb3q161.jpg'&gt;...</td>\n",
       "      <td>red cornetfish (*Fistularia petimba*)</td>\n",
       "      <td>[Japan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2020-11-13 06:34:11</td>\n",
       "      <td>jtbhpj</td>\n",
       "      <td>Thought it was a baby lingcod but it doesn’t h...</td>\n",
       "      <td>Identified, high confidence</td>\n",
       "      <td>&lt;a href='https://www.reddit.com/gallery/jtbhpj...</td>\n",
       "      <td>Pacific staghorn sculpin *Leptocottus armatus*...</td>\n",
       "      <td>[Caught, Newport Beach Ca, Need ID]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2020-09-28 02:08:47</td>\n",
       "      <td>j11sg7</td>\n",
       "      <td>Most beautiful sunfish I caught</td>\n",
       "      <td>Identified, high confidence</td>\n",
       "      <td>&lt;a href='https://www.reddit.com/gallery/j11sg7...</td>\n",
       "      <td>I think the first one is a Readbreast Sunfish....</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2020-08-30 18:24:23</td>\n",
       "      <td>ijffix</td>\n",
       "      <td>[North Myrtle Beach, SC] I was fishing along t...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://i.imgur.com/CVqCZsx.jpg'&gt;98&lt;/a&gt;</td>\n",
       "      <td>Looks like Barracuda jaws</td>\n",
       "      <td>[North Myrtle Beach, SC, Intracoastal Waterway]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2020-08-03 01:37:53</td>\n",
       "      <td>i2maf5</td>\n",
       "      <td>My dad caught this by accident in Puget Sound,...</td>\n",
       "      <td>Identified, high confidence</td>\n",
       "      <td>&lt;a href='https://i.redd.it/if6r0xredoe51.jpg'&gt;...</td>\n",
       "      <td>100% pacific spiny dogfish</td>\n",
       "      <td>[Puget Sound]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date      ID  \\\n",
       "0  2020-10-26 04:40:05  ji7jvh   \n",
       "1  2020-06-15 00:58:58  h93riw   \n",
       "2  2020-05-11 17:59:31  ghq9mn   \n",
       "3  2021-01-21 17:49:37  l2299m   \n",
       "4  2020-11-20 22:01:29  jxxfdr   \n",
       "..                 ...     ...   \n",
       "95 2020-11-27 07:00:16  k1vk0j   \n",
       "96 2020-11-13 06:34:11  jtbhpj   \n",
       "97 2020-09-28 02:08:47  j11sg7   \n",
       "98 2020-08-30 18:24:23  ijffix   \n",
       "99 2020-08-03 01:37:53  i2maf5   \n",
       "\n",
       "                                                Title  \\\n",
       "0   Anybody know what species this is? Found in Ja...   \n",
       "1   Caught in key west, Florida. Never seen anythi...   \n",
       "2   I found this video and the fish is hella cute ...   \n",
       "3   Picture taken in Central Florida. Freshwater p...   \n",
       "4   What's this crustacean? Has a short lobster li...   \n",
       "..                                                ...   \n",
       "95  What is this \"rare elongated fish\" caught off ...   \n",
       "96  Thought it was a baby lingcod but it doesn’t h...   \n",
       "97                    Most beautiful sunfish I caught   \n",
       "98  [North Myrtle Beach, SC] I was fishing along t...   \n",
       "99  My dad caught this by accident in Puget Sound,...   \n",
       "\n",
       "                                 Flair  \\\n",
       "0                 Identified, probably   \n",
       "1          Identified, high confidence   \n",
       "2                                 None   \n",
       "3   Family known, species unidentified   \n",
       "4          Identified, high confidence   \n",
       "..                                 ...   \n",
       "95         Identified, high confidence   \n",
       "96         Identified, high confidence   \n",
       "97         Identified, high confidence   \n",
       "98                                None   \n",
       "99         Identified, high confidence   \n",
       "\n",
       "                                                  URL  \\\n",
       "0   <a href='https://i.redd.it/bybemwp61dv51.jpg'>...   \n",
       "1   <a href='https://i.redd.it/j86d87vnhy451.jpg'>...   \n",
       "2     <a href='https://v.redd.it/lvximb7tr5y41'>2</a>   \n",
       "3   <a href='https://i.redd.it/ow7f7ozctpc61.jpg'>...   \n",
       "4     <a href='https://v.redd.it/c8cfmpcrlg061'>4</a>   \n",
       "..                                                ...   \n",
       "95  <a href='https://i.redd.it/8nxx9mfb3q161.jpg'>...   \n",
       "96  <a href='https://www.reddit.com/gallery/jtbhpj...   \n",
       "97  <a href='https://www.reddit.com/gallery/j11sg7...   \n",
       "98   <a href='https://i.imgur.com/CVqCZsx.jpg'>98</a>   \n",
       "99  <a href='https://i.redd.it/if6r0xredoe51.jpg'>...   \n",
       "\n",
       "                                          Top Comment  \\\n",
       "0   Florida pompano,  *Trachinotus carolinus* . Th...   \n",
       "1   Took me awhile, but its a swallow-tailed bass ...   \n",
       "2   Looks like spotted porcupinefish also known as...   \n",
       "3        Common pleco. Non-native species in Florida.   \n",
       "4                  Pretty sure its a Slipper Lobster.   \n",
       "..                                                ...   \n",
       "95              red cornetfish (*Fistularia petimba*)   \n",
       "96  Pacific staghorn sculpin *Leptocottus armatus*...   \n",
       "97  I think the first one is a Readbreast Sunfish....   \n",
       "98                          Looks like Barracuda jaws   \n",
       "99                         100% pacific spiny dogfish   \n",
       "\n",
       "                                           Location  \n",
       "0                  [Anybody, Jacksonville, Inshore]  \n",
       "1                                 [Caught, Florida]  \n",
       "2                                                []  \n",
       "3            [Picture, Central Florida, Freshwater]  \n",
       "4                                         [Florida]  \n",
       "..                                              ...  \n",
       "95                                          [Japan]  \n",
       "96              [Caught, Newport Beach Ca, Need ID]  \n",
       "97                                               []  \n",
       "98  [North Myrtle Beach, SC, Intracoastal Waterway]  \n",
       "99                                    [Puget Sound]  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Location\"] = location\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
