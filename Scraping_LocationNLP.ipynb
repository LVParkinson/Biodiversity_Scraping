{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural Observer\n",
    "\n",
    "A project to collect the thousands of observations of the natural world from Reddit (and maybe eventually other social media). Photos, identification, and any location information are collated to create a usable dataset for citizen science networks such as eBird and iNaturalist. We hope...\n",
    "\n",
    "Created by:\n",
    "Lindsey Parkinson, Thomas Oliver, and Roman Grisch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/../redditkeys.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9741f22327fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/../redditkeys.json\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mcredentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m reddit = praw.Reddit(client_id = credentials[\"client_id\"],\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/../redditkeys.json'"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "#redditkeys.json contains all the information necessary to use the Reddit API\n",
    "\n",
    "with open(\"/../redditkeys.json\") as infile:\n",
    "    credentials = json.load(infile)\n",
    "reddit = praw.Reddit(client_id = credentials[\"client_id\"],\n",
    "                     client_secret = credentials[\"client_secret\"],\n",
    "                     user_agent=credentials[\"user_agent\"],\n",
    "                     username=credentials[\"username\"],\n",
    "                     password=credentials[\"password\"])\n",
    "\n",
    "print(reddit.user.me())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whatisthisfish completed; total 5 posts has been scraped\n",
      "whatsthisfish completed; total 10 posts has been scraped\n"
     ]
    }
   ],
   "source": [
    "date_list = []\n",
    "author_list = []\n",
    "id_list = []\n",
    "link_flair_text_list = []\n",
    "#num_comments_list = []\n",
    "#score_list = []\n",
    "title_list = []\n",
    "#upvote_ratio_list = []\n",
    "url_list = []\n",
    "\n",
    "\n",
    "#subreddits we want to scrape information from\n",
    "subreddit_list=  ['whatisthisfish',\n",
    "                  'whatsthisfish'\n",
    "                  #'whatsthisbug',\n",
    "                  #'whatsthisbird',\n",
    "                  #'whatsthissnake',\n",
    "                 ]\n",
    "\n",
    "#What information we want from each subreddit post\n",
    "for subred in subreddit_list:\n",
    "    subreddit = reddit.subreddit(subred)\n",
    "    top_post = subreddit.top(limit = 5)  \n",
    "    \n",
    "    for sub in top_post: \n",
    "        #if link_flair_text_list.append(sub.link_flair_text != 'Solved'):\n",
    "            #continue\n",
    "        \n",
    "        date_list.append(datetime.datetime.fromtimestamp(sub.created_utc))\n",
    "        author_list.append(sub.author)\n",
    "        id_list.append(sub.id)        \n",
    "        link_flair_text_list.append(sub.link_flair_text)\n",
    "        #num_comments_list.append(sub.num_comments)\n",
    "        #score_list.append(sub.score)\n",
    "        title_list.append(sub.title)\n",
    "        #upvote_ratio_list.append(sub.upvote_ratio) \n",
    "        url_list.append(sub.url)\n",
    "        \n",
    "    print(subred, 'completed; ', end='')\n",
    "    print('total', len(author_list), 'posts has been scraped')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(row, col = \"URL\"):\n",
    "    \"\"\"\n",
    "    This function will convert strings into hyperlinks, makes it easier to pull images\n",
    "    \"\"\"\n",
    "    return \"<a href='{}'>{}</a>\".format(row[col], row.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Date': date_list,\n",
    "                   'ID':id_list, \n",
    "                   'Author':author_list, \n",
    "                   'Title':title_list,\n",
    "                   #'Count_of_Comments':num_comments_list,\n",
    "                   #'Upvote_Count':score_list,\n",
    "                   #'Upvote_Ratio':upvote_ratio_list,\n",
    "                   'Flair':link_flair_text_list,\n",
    "                   'URL':url_list\n",
    "                  })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['URL'] = df.apply(convert, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ID</th>\n",
       "      <th>Author</th>\n",
       "      <th>Title</th>\n",
       "      <th>Flair</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-17 19:45:23</td>\n",
       "      <td>f5denb</td>\n",
       "      <td>officialjoeyacnl</td>\n",
       "      <td>found at a pet store any ideas? image is a kno...</td>\n",
       "      <td>Solved</td>\n",
       "      <td>&lt;a href='https://i.redd.it/f6ntf9ys4jh41.jpg'&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-07 04:46:15</td>\n",
       "      <td>fwcjf9</td>\n",
       "      <td>Shinobi-butterstick</td>\n",
       "      <td>what type of fish is this?</td>\n",
       "      <td>Solved</td>\n",
       "      <td>&lt;a href='https://i.redd.it/yxwvpygg7br41.jpg'&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-27 00:07:36</td>\n",
       "      <td>hyfvpv</td>\n",
       "      <td>xItsMeGradyMC</td>\n",
       "      <td>What's this fish? Oh that, that's a bluegill</td>\n",
       "      <td>Solved</td>\n",
       "      <td>&lt;a href='https://i.redd.it/k6rb9y0wy9d51.png'&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-17 14:48:48</td>\n",
       "      <td>f58z6m</td>\n",
       "      <td>jcole315315</td>\n",
       "      <td>Caught in New Jersey, what is this fish?</td>\n",
       "      <td>Unsolved</td>\n",
       "      <td>&lt;a href='https://i.redd.it/ljqoyz43ohh41.jpg'&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-29 23:44:45</td>\n",
       "      <td>i09fvp</td>\n",
       "      <td>PhotonicBoom21</td>\n",
       "      <td>FAQ: Common sunfish in North America</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://i.redd.it/brfh2rkh9vd51.jpg'&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-06-15 00:58:58</td>\n",
       "      <td>h93riw</td>\n",
       "      <td>oceanjunkie</td>\n",
       "      <td>Caught in key west, Florida. Never seen anythi...</td>\n",
       "      <td>Identified, high confidence</td>\n",
       "      <td>&lt;a href='https://i.redd.it/j86d87vnhy451.jpg'&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-05-11 17:59:31</td>\n",
       "      <td>ghq9mn</td>\n",
       "      <td>edgy_edgy_edgy</td>\n",
       "      <td>I found this video and the fish is hella cute ...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://v.redd.it/lvximb7tr5y41'&gt;6&lt;/a&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-03-13 11:38:36</td>\n",
       "      <td>fhxmse</td>\n",
       "      <td>wirapori</td>\n",
       "      <td>Came across this jellyfish at my dad's saltwat...</td>\n",
       "      <td>Identification question</td>\n",
       "      <td>&lt;a href='https://v.redd.it/c6k4lgvk4fm41'&gt;7&lt;/a&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-06-12 15:25:32</td>\n",
       "      <td>h7kn6s</td>\n",
       "      <td>rnotjimmy</td>\n",
       "      <td>Caught deep sea fishing off the coast of Looe,...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://i.redd.it/klx4m6aodh451.jpg'&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-05-06 03:06:08</td>\n",
       "      <td>bl5kr6</td>\n",
       "      <td>hay-guise</td>\n",
       "      <td>What's this fish skeleton? Found in a friend's...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://i.redd.it/t6h2o3tcqhw21.jpg'&gt;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date      ID               Author  \\\n",
       "0 2020-02-17 19:45:23  f5denb     officialjoeyacnl   \n",
       "1 2020-04-07 04:46:15  fwcjf9  Shinobi-butterstick   \n",
       "2 2020-07-27 00:07:36  hyfvpv        xItsMeGradyMC   \n",
       "3 2020-02-17 14:48:48  f58z6m          jcole315315   \n",
       "4 2020-07-29 23:44:45  i09fvp       PhotonicBoom21   \n",
       "5 2020-06-15 00:58:58  h93riw          oceanjunkie   \n",
       "6 2020-05-11 17:59:31  ghq9mn       edgy_edgy_edgy   \n",
       "7 2020-03-13 11:38:36  fhxmse             wirapori   \n",
       "8 2020-06-12 15:25:32  h7kn6s            rnotjimmy   \n",
       "9 2019-05-06 03:06:08  bl5kr6            hay-guise   \n",
       "\n",
       "                                               Title  \\\n",
       "0  found at a pet store any ideas? image is a kno...   \n",
       "1                         what type of fish is this?   \n",
       "2       What's this fish? Oh that, that's a bluegill   \n",
       "3           Caught in New Jersey, what is this fish?   \n",
       "4               FAQ: Common sunfish in North America   \n",
       "5  Caught in key west, Florida. Never seen anythi...   \n",
       "6  I found this video and the fish is hella cute ...   \n",
       "7  Came across this jellyfish at my dad's saltwat...   \n",
       "8  Caught deep sea fishing off the coast of Looe,...   \n",
       "9  What's this fish skeleton? Found in a friend's...   \n",
       "\n",
       "                         Flair  \\\n",
       "0                       Solved   \n",
       "1                       Solved   \n",
       "2                       Solved   \n",
       "3                     Unsolved   \n",
       "4                         None   \n",
       "5  Identified, high confidence   \n",
       "6                         None   \n",
       "7      Identification question   \n",
       "8                         None   \n",
       "9                         None   \n",
       "\n",
       "                                                 URL  \n",
       "0  <a href='https://i.redd.it/f6ntf9ys4jh41.jpg'>...  \n",
       "1  <a href='https://i.redd.it/yxwvpygg7br41.jpg'>...  \n",
       "2  <a href='https://i.redd.it/k6rb9y0wy9d51.png'>...  \n",
       "3  <a href='https://i.redd.it/ljqoyz43ohh41.jpg'>...  \n",
       "4  <a href='https://i.redd.it/brfh2rkh9vd51.jpg'>...  \n",
       "5  <a href='https://i.redd.it/j86d87vnhy451.jpg'>...  \n",
       "6    <a href='https://v.redd.it/lvximb7tr5y41'>6</a>  \n",
       "7    <a href='https://v.redd.it/c6k4lgvk4fm41'>7</a>  \n",
       "8  <a href='https://i.redd.it/klx4m6aodh451.jpg'>...  \n",
       "9  <a href='https://i.redd.it/t6h2o3tcqhw21.jpg'>...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = defaultdict(list)\n",
    "for blue in id_list:\n",
    "    submission = reddit.submission(str(blue))\n",
    "    for top_level_comment in submission.comments:\n",
    "        comments[submission.title].append(top_level_comment.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_comment = list()\n",
    "for x in comments.values():\n",
    "    top_comment.append(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Top Comment\"] = top_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ID</th>\n",
       "      <th>Author</th>\n",
       "      <th>Title</th>\n",
       "      <th>Flair</th>\n",
       "      <th>URL</th>\n",
       "      <th>Top Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-17 19:45:23</td>\n",
       "      <td>f5denb</td>\n",
       "      <td>officialjoeyacnl</td>\n",
       "      <td>found at a pet store any ideas? image is a kno...</td>\n",
       "      <td>Solved</td>\n",
       "      <td>&lt;a href='https://i.redd.it/f6ntf9ys4jh41.jpg'&gt;...</td>\n",
       "      <td>Flowerhorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-07 04:46:15</td>\n",
       "      <td>fwcjf9</td>\n",
       "      <td>Shinobi-butterstick</td>\n",
       "      <td>what type of fish is this?</td>\n",
       "      <td>Solved</td>\n",
       "      <td>&lt;a href='https://i.redd.it/yxwvpygg7br41.jpg'&gt;...</td>\n",
       "      <td>Scarus coeruleus, blue parrotfish! They are in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-27 00:07:36</td>\n",
       "      <td>hyfvpv</td>\n",
       "      <td>xItsMeGradyMC</td>\n",
       "      <td>What's this fish? Oh that, that's a bluegill</td>\n",
       "      <td>Solved</td>\n",
       "      <td>&lt;a href='https://i.redd.it/k6rb9y0wy9d51.png'&gt;...</td>\n",
       "      <td>I wonder if it calls me pink lung.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-17 14:48:48</td>\n",
       "      <td>f58z6m</td>\n",
       "      <td>jcole315315</td>\n",
       "      <td>Caught in New Jersey, what is this fish?</td>\n",
       "      <td>Unsolved</td>\n",
       "      <td>&lt;a href='https://i.redd.it/ljqoyz43ohh41.jpg'&gt;...</td>\n",
       "      <td>Seaweed blenny.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-29 23:44:45</td>\n",
       "      <td>i09fvp</td>\n",
       "      <td>PhotonicBoom21</td>\n",
       "      <td>FAQ: Common sunfish in North America</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://i.redd.it/brfh2rkh9vd51.jpg'&gt;...</td>\n",
       "      <td>Recently we have been seeing a *lot* of sunfis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-06-15 00:58:58</td>\n",
       "      <td>h93riw</td>\n",
       "      <td>oceanjunkie</td>\n",
       "      <td>Caught in key west, Florida. Never seen anythi...</td>\n",
       "      <td>Identified, high confidence</td>\n",
       "      <td>&lt;a href='https://i.redd.it/j86d87vnhy451.jpg'&gt;...</td>\n",
       "      <td>Took me awhile, but its a swallow-tailed bass ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-05-11 17:59:31</td>\n",
       "      <td>ghq9mn</td>\n",
       "      <td>edgy_edgy_edgy</td>\n",
       "      <td>I found this video and the fish is hella cute ...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://v.redd.it/lvximb7tr5y41'&gt;6&lt;/a&gt;</td>\n",
       "      <td>Looks like spotted porcupinefish also known as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-03-13 11:38:36</td>\n",
       "      <td>fhxmse</td>\n",
       "      <td>wirapori</td>\n",
       "      <td>Came across this jellyfish at my dad's saltwat...</td>\n",
       "      <td>Identification question</td>\n",
       "      <td>&lt;a href='https://v.redd.it/c6k4lgvk4fm41'&gt;7&lt;/a&gt;</td>\n",
       "      <td>Hey it looks like a [Lobonema Smithii](https:/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-06-12 15:25:32</td>\n",
       "      <td>h7kn6s</td>\n",
       "      <td>rnotjimmy</td>\n",
       "      <td>Caught deep sea fishing off the coast of Looe,...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://i.redd.it/klx4m6aodh451.jpg'&gt;...</td>\n",
       "      <td>I’m going with Tub Gurnard.  https://en.m.wiki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-05-06 03:06:08</td>\n",
       "      <td>bl5kr6</td>\n",
       "      <td>hay-guise</td>\n",
       "      <td>What's this fish skeleton? Found in a friend's...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://i.redd.it/t6h2o3tcqhw21.jpg'&gt;...</td>\n",
       "      <td>Raphael catfish or close relative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date      ID               Author  \\\n",
       "0 2020-02-17 19:45:23  f5denb     officialjoeyacnl   \n",
       "1 2020-04-07 04:46:15  fwcjf9  Shinobi-butterstick   \n",
       "2 2020-07-27 00:07:36  hyfvpv        xItsMeGradyMC   \n",
       "3 2020-02-17 14:48:48  f58z6m          jcole315315   \n",
       "4 2020-07-29 23:44:45  i09fvp       PhotonicBoom21   \n",
       "5 2020-06-15 00:58:58  h93riw          oceanjunkie   \n",
       "6 2020-05-11 17:59:31  ghq9mn       edgy_edgy_edgy   \n",
       "7 2020-03-13 11:38:36  fhxmse             wirapori   \n",
       "8 2020-06-12 15:25:32  h7kn6s            rnotjimmy   \n",
       "9 2019-05-06 03:06:08  bl5kr6            hay-guise   \n",
       "\n",
       "                                               Title  \\\n",
       "0  found at a pet store any ideas? image is a kno...   \n",
       "1                         what type of fish is this?   \n",
       "2       What's this fish? Oh that, that's a bluegill   \n",
       "3           Caught in New Jersey, what is this fish?   \n",
       "4               FAQ: Common sunfish in North America   \n",
       "5  Caught in key west, Florida. Never seen anythi...   \n",
       "6  I found this video and the fish is hella cute ...   \n",
       "7  Came across this jellyfish at my dad's saltwat...   \n",
       "8  Caught deep sea fishing off the coast of Looe,...   \n",
       "9  What's this fish skeleton? Found in a friend's...   \n",
       "\n",
       "                         Flair  \\\n",
       "0                       Solved   \n",
       "1                       Solved   \n",
       "2                       Solved   \n",
       "3                     Unsolved   \n",
       "4                         None   \n",
       "5  Identified, high confidence   \n",
       "6                         None   \n",
       "7      Identification question   \n",
       "8                         None   \n",
       "9                         None   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  <a href='https://i.redd.it/f6ntf9ys4jh41.jpg'>...   \n",
       "1  <a href='https://i.redd.it/yxwvpygg7br41.jpg'>...   \n",
       "2  <a href='https://i.redd.it/k6rb9y0wy9d51.png'>...   \n",
       "3  <a href='https://i.redd.it/ljqoyz43ohh41.jpg'>...   \n",
       "4  <a href='https://i.redd.it/brfh2rkh9vd51.jpg'>...   \n",
       "5  <a href='https://i.redd.it/j86d87vnhy451.jpg'>...   \n",
       "6    <a href='https://v.redd.it/lvximb7tr5y41'>6</a>   \n",
       "7    <a href='https://v.redd.it/c6k4lgvk4fm41'>7</a>   \n",
       "8  <a href='https://i.redd.it/klx4m6aodh451.jpg'>...   \n",
       "9  <a href='https://i.redd.it/t6h2o3tcqhw21.jpg'>...   \n",
       "\n",
       "                                         Top Comment  \n",
       "0                                         Flowerhorn  \n",
       "1  Scarus coeruleus, blue parrotfish! They are in...  \n",
       "2                 I wonder if it calls me pink lung.  \n",
       "3                                    Seaweed blenny.  \n",
       "4  Recently we have been seeing a *lot* of sunfis...  \n",
       "5  Took me awhile, but its a swallow-tailed bass ...  \n",
       "6  Looks like spotted porcupinefish also known as...  \n",
       "7  Hey it looks like a [Lobonema Smithii](https:/...  \n",
       "8  I’m going with Tub Gurnard.  https://en.m.wiki...  \n",
       "9                  Raphael catfish or close relative  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/lindsey/nltk_data...\n",
      "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data] Downloading package words to /home/lindsey/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/lindsey/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import and download NLP tools\n",
    "\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.copy of 0    found at a pet store any ideas? image is a kno...\n",
      "1                           what type of fish is this?\n",
      "2         What's this fish? Oh that, that's a bluegill\n",
      "3             Caught in New Jersey, what is this fish?\n",
      "4                 FAQ: Common sunfish in North America\n",
      "5    Caught in key west, Florida. Never seen anythi...\n",
      "6    I found this video and the fish is hella cute ...\n",
      "7    Came across this jellyfish at my dad's saltwat...\n",
      "8    Caught deep sea fishing off the coast of Looe,...\n",
      "9    What's this fish skeleton? Found in a friend's...\n",
      "Name: Title, dtype: object>\n",
      "['found at a pet store any ideas? image is a known image too', 'what type of fish is this?', \"What's this fish? Oh that, that's a bluegill\", 'Caught in New Jersey, what is this fish?', 'FAQ: Common sunfish in North America', 'Caught in key west, Florida. Never seen anything like it.', 'I found this video and the fish is hella cute but I dont know what kind of fish it is', \"Came across this jellyfish at my dad's saltwater fish farm in Brunei. The farm is located besides the Mentiri golf course. Any idea what the species is called?\", 'Caught deep sea fishing off the coast of Looe, Cornwall when I was a teen around 13 years ago. Sure I was told at the time but forgot the name and lost the photo until now! Any ideas?', \"What's this fish skeleton? Found in a friend's yard this week, in Southern CA.\"]\n"
     ]
    }
   ],
   "source": [
    "practice = df[\"Title\"].copy\n",
    "print(practice)\n",
    "\n",
    "print(df[\"Title\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Caught', 'New Jersey', 'FAQ', 'North America', 'Caught', 'Florida', 'Came', 'Brunei', 'Mentiri', 'Caught', 'Looe', 'Cornwall', 'Southern CA']\n"
     ]
    }
   ],
   "source": [
    "#A function to pull location information from Reddit post titles\n",
    "\n",
    "#with open('sample.txt', 'r') as f:\n",
    "out_str = \",\"\n",
    "sample = out_str.join(df['Title'])\n",
    "\n",
    "\n",
    "sentences = nltk.sent_tokenize(sample)\n",
    "tokenized_sentences = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "tagged_sentences = [nltk.pos_tag(sentence) for sentence in tokenized_sentences]\n",
    "chunked_sentences = nltk.ne_chunk_sents(tagged_sentences, binary=True)\n",
    "\n",
    "def extract_entity_names(t):\n",
    "    entity_names = []\n",
    "\n",
    "    if hasattr(t, 'label') and t.label:\n",
    "        if t.label() == 'NE':\n",
    "            entity_names.append(' '.join([child[0] for child in t]))\n",
    "        else:\n",
    "            for child in t:\n",
    "                entity_names.extend(extract_entity_names(child))\n",
    "\n",
    "    return entity_names\n",
    "\n",
    "entity_names = []\n",
    "for tree in chunked_sentences:\n",
    "    # Print results per sentence\n",
    "    # print extract_entity_names(tree)\n",
    "\n",
    "    entity_names.extend(extract_entity_names(tree))\n",
    "\n",
    "# Print all entity names\n",
    "#print entity_names\n",
    "\n",
    "# Print unique entity names\n",
    "print(entity_names)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function grabs all the location words but is also attracted to the word \"caught\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
